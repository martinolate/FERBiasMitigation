{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f50146e4-5e50-40e5-ba51-fa3099b555ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All files renamed successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Base dataset path\n",
    "BASE_DIR = \"/cluster/home/miolate21/FER_biasmitigation1/data/\"\n",
    "datasets = ['fer2013', 'ckplus', 'rafdb']\n",
    "\n",
    "for dataset in datasets:\n",
    "    for split in ['train', 'test']:\n",
    "        split_path = os.path.join(BASE_DIR, dataset, split)\n",
    "        if not os.path.exists(split_path):\n",
    "            continue\n",
    "\n",
    "        for emotion in os.listdir(split_path):\n",
    "            emotion_path = os.path.join(split_path, emotion)\n",
    "            if not os.path.isdir(emotion_path):\n",
    "                continue\n",
    "\n",
    "            images = sorted(os.listdir(emotion_path))  # Sort for reproducibility\n",
    "\n",
    "            for idx, img_name in enumerate(images):\n",
    "                src = os.path.join(emotion_path, img_name)\n",
    "\n",
    "                # Skip non-files (e.g., directories like .ipynb_checkpoints)\n",
    "                if not os.path.isfile(src) or img_name.startswith('.'):\n",
    "                    continue\n",
    "\n",
    "                dst_name = f\"{emotion}_{dataset}_{split}_{idx:05d}.jpg\"\n",
    "                dst = os.path.join(emotion_path, dst_name)\n",
    "\n",
    "                os.rename(src, dst)\n",
    "\n",
    "print(\"✅ All files renamed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ff6a28-ad13-4027-96ae-9743dd803eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fer2013 train neutral: 100%|██████████| 4965/4965 [00:03<00:00, 1337.44it/s]\n",
      "fer2013 train happy:  88%|████████▊ | 6376/7216 [00:04<00:00, 1344.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping non-file /cluster/home/miolate21/FER_biasmitigation1/data/fer2013/train/happy/happy_fer2013_train_00000.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fer2013 train happy: 100%|██████████| 7216/7216 [00:05<00:00, 1346.76it/s]\n",
      "fer2013 train surprise: 100%|██████████| 3171/3171 [00:02<00:00, 1340.77it/s]\n",
      "fer2013 train fear: 100%|██████████| 4097/4097 [00:03<00:00, 1336.31it/s]\n",
      "fer2013 train disgust: 100%|██████████| 436/436 [00:00<00:00, 1347.68it/s]\n",
      "fer2013 train sad: 100%|██████████| 4830/4830 [00:03<00:00, 1343.52it/s]\n",
      "fer2013 train angry:  37%|███▋      | 1474/3996 [00:01<00:01, 1335.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping non-file /cluster/home/miolate21/FER_biasmitigation1/data/fer2013/train/angry/angry_fer2013_train_00000.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fer2013 train angry: 100%|██████████| 3996/3996 [00:02<00:00, 1333.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# ====== Cell 1: Load Libraries ======\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ====== Cell 2: Define Paths and Setup ======\n",
    "BASE_DIR = \"/cluster/home/miolate21/FER_biasmitigation1/data\"\n",
    "datasets = ['fer2013', 'ckplus', 'rafdb']\n",
    "splits = ['train', 'test']\n",
    "\n",
    "IMG_SIZE = (224, 224)  # ResNet50 input size\n",
    "emotion_to_idx = {\n",
    "    'angry': 0,\n",
    "    'disgust': 1,\n",
    "    'fear': 2,\n",
    "    'happy': 3,\n",
    "    'neutral': 4,\n",
    "    'sad': 5,\n",
    "    'surprise': 6\n",
    "}\n",
    "\n",
    "# ====== Cell 3: Load Images and Labels ======\n",
    "def load_dataset(dataset, split):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    split_dir = os.path.join(BASE_DIR, dataset, split)\n",
    "    if not os.path.exists(split_dir):\n",
    "        return np.array(images), np.array(labels)  # Empty arrays\n",
    "\n",
    "    for emotion in os.listdir(split_dir):\n",
    "        if emotion.startswith('.'):\n",
    "            continue  \n",
    "\n",
    "        emotion_path = os.path.join(split_dir, emotion)\n",
    "        if not os.path.isdir(emotion_path):\n",
    "            continue\n",
    "\n",
    "        img_files = os.listdir(emotion_path)\n",
    "\n",
    "        for img_file in tqdm(img_files, desc=f\"{dataset} {split} {emotion}\"):\n",
    "            img_path = os.path.join(emotion_path, img_file)\n",
    "\n",
    "            if not os.path.isfile(img_path):\n",
    "                print(f\"Skipping non-file {img_path}\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                img = image.load_img(img_path, color_mode='rgb', target_size=IMG_SIZE)\n",
    "                img_array = image.img_to_array(img)\n",
    "\n",
    "                images.append(img_array)\n",
    "                labels.append(emotion_to_idx.get(emotion.split('_')[0], 0))  \n",
    "            except Exception as e:\n",
    "                print(f\"Skipping file {img_path}: {e}\")\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# ====== Cell 4: Load all datasets ======\n",
    "X_train, y_train = [], []\n",
    "X_test, y_test = [], []\n",
    "\n",
    "for dataset in datasets:\n",
    "    X_tr, y_tr = load_dataset(dataset, \"train\")\n",
    "    X_te, y_te = load_dataset(dataset, \"test\")\n",
    "\n",
    "    X_train.append(X_tr)\n",
    "    y_train.append(y_tr)\n",
    "    X_test.append(X_te)\n",
    "    y_test.append(y_te)\n",
    "\n",
    "# Concatenate everything\n",
    "X_train = np.concatenate(X_train, axis=0)\n",
    "y_train = np.concatenate(y_train, axis=0)\n",
    "X_test = np.concatenate(X_test, axis=0)\n",
    "y_test = np.concatenate(y_test, axis=0)\n",
    "\n",
    "print(f\"Training samples: {X_train.shape}\")\n",
    "print(f\"Testing samples: {X_test.shape}\")\n",
    "\n",
    "# ====== Cell 5: Preprocess for ResNet50 ======\n",
    "X_train = preprocess_input(X_train)\n",
    "X_test = preprocess_input(X_test)\n",
    "\n",
    "print(\"✅ Preprocessing complete.\")\n",
    "\n",
    "# ====== Cell 6: Save final arrays ======\n",
    "output_dir = '/cluster/home/miolate21/FER_biasmitigation1/data_preprocessed/'\n",
    "os.makedirs(output_dir, exist_ok=True)  # Make sure the folder exists\n",
    "\n",
    "np.save(os.path.join(output_dir, 'X_train.npy'), X_train)\n",
    "np.save(os.path.join(output_dir, 'y_train.npy'), y_train)\n",
    "np.save(os.path.join(output_dir, 'X_test.npy'), X_test)\n",
    "np.save(os.path.join(output_dir, 'y_test.npy'), y_test)\n",
    "\n",
    "print(\"✅ All datasets saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803472a7-a397-4f3a-8a28-beee2f954485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ X_train, y_train, X_test, y_test already loaded.\n"
     ]
    }
   ],
   "source": [
    "# ===== Auto-create processed_data.npz safely =====\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Paths\n",
    "preprocessed_dir = '/cluster/home/miolate21/FER_biasmitigation1/data_preprocessed/'\n",
    "npz_save_path = '/cluster/home/miolate21/FER_biasmitigation1/data_preprocessed/processed_data.npz'\n",
    "\n",
    "# Step 1: Check if variables exist\n",
    "need_reload = False\n",
    "try:\n",
    "    _ = X_train.shape\n",
    "    _ = y_train.shape\n",
    "    _ = X_test.shape\n",
    "    _ = y_test.shape\n",
    "    print(\"✅ X_train, y_train, X_test, y_test already loaded.\")\n",
    "except NameError:\n",
    "    need_reload = True\n",
    "    print(\"⚠️ Variables not found in memory. Will reload from .npy files.\")\n",
    "\n",
    "# Step 2: Reload if needed\n",
    "if need_reload:\n",
    "    print(\"🔄 Reloading arrays from preprocessed .npy files...\")\n",
    "    X_train = np.load(os.path.join(preprocessed_dir, 'X_train.npy'))\n",
    "    y_train = np.load(os.path.join(preprocessed_dir, 'y_train.npy'))\n",
    "    X_test = np.load(os.path.join(preprocessed_dir, 'X_test.npy'))\n",
    "    y_test = np.load(os.path.join(preprocessed_dir, 'y_test.npy'))\n",
    "    print(f\"✅ Reloaded! Shapes: X_train {X_train.shape}, X_test {X_test.shape}\")\n",
    "\n",
    "# Step 3: Save into .npz\n",
    "os.makedirs(os.path.dirname(npz_save_path), exist_ok=True)  \n",
    "\n",
    "np.savez(\n",
    "    npz_save_path,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test\n",
    ")\n",
    "\n",
    "print(f\"✅ Saved processed_data.npz at: {npz_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3334c968-e8c5-4d68-b2c3-f96c369858d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (3.12)",
   "language": "python",
   "name": "py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
